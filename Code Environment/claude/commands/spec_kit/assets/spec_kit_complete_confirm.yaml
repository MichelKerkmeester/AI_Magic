# ───────────────────────────────────────────────────────────────────
# SMART SPECKIT: COMPLETE WORKFLOW (INTERACTIVE MODE)
# ───────────────────────────────────────────────────────────────────
role: Expert Developer using Smart SpecKit with user confirmation
purpose: Spec-driven development with mandatory compliance and step-by-step approval
action: Run full SpecKit from spec to implementation with user checkpoints

operating_mode:
  workflow: sequential
  workflow_compliance: MANDATORY
  workflow_execution: interactive
  approvals: step_by_step
  tracking: progressive_task_checklists
  validation: checkpoint_based

development_philosophy:
  principle: "Quality first, velocity second"
  approach: "Complete lifecycle with user-validated checkpoints"
  mandate: "Plan thoroughly, review with user, implement carefully, verify continuously"

# ───────────────────────────────────────────────────────────────────
# USER INPUTS (Transformed from raw text)
# ───────────────────────────────────────────────────────────────────
user_inputs:
  git_branch: |
    [GIT_BRANCH]
    Git branch name for the work. Leave empty to auto-create as
    feature-{NNN} from highest existing number + 1.

  spec_folder: |
    [SPEC_FOLDER]
    Spec folder path. Leave empty to auto-create next available.

  context: |
    [CONTEXT]
    Background information, constraints, or existing documentation.

  issues: |
    [ISSUES]
    Known issues, problems, or concerns to address.

  request: |
    [REQUEST]
    Complete work to be done. REQUIRED.

  environment: |
    [STAGING LINK]
    Staging or production URL for browser testing.

  scope: |
    [FILES]
    Files or folders to work with.

# ─────────────────────────────────────────────────────────────────
# FIELD HANDLING
# ─────────────────────────────────────────────────────────────────
field_handling:
  spec_id:
    derive_from: "spec_folder path using pattern specs/{NNN} or specs/{NNN-name}"
    fallback: "Extract numeric portion or use timestamp if extraction fails"

  defaults:
    git_branch_empty: "Auto-create feature-{NNN} from highest +001"
    spec_folder_empty: "Auto-create specs/{NNN} from highest +001"
    context_empty: "Infer from [REQUEST], [STAGING LINK], and codebase exploration"
    issues_empty: "Investigate and discover during workflow"
    environment_empty: "Skip browser testing steps"
    scope_empty: "Use scope_policy.default"

  scope_policy:
    default: "specs/**"
    rule: "Limit file operations to scope when provided"

# ─────────────────────────────────────────────────────────────────
# DOCUMENTATION LEVELS (Progressive Enhancement)
# ─────────────────────────────────────────────────────────────────
documentation_levels:
  level_1_baseline:
    name: "Level 1 (Baseline)"
    required_files:
    - spec.md
    - plan.md
    - tasks.md
    loc_guidance: "<100 LOC"
    use_case: "Simple changes, bug fixes, minor features"

  level_2_verification:
    name: "Level 2 (Verification)"
    required_files:
    - spec.md
    - plan.md
    - tasks.md
    - checklist.md
    loc_guidance: "100-499 LOC"
    use_case: "Medium features, refactoring, multi-file changes"

  level_3_full:
    name: "Level 3 (Full)"
    required_files:
    - spec.md
    - plan.md
    - tasks.md
    - checklist.md
    - decision-record.md
    optional_files:
    - research-spike.md
    loc_guidance: ">=500 LOC"
    use_case: "Complex features, architecture changes, high-risk modifications"

  level_selection:
    note: "LOC thresholds are SOFT GUIDANCE - choose level based on complexity and risk"
    default: "Level 1 for simple tasks, escalate based on analysis"

# ─────────────────────────────────────────────────────────────────
# AVAILABLE TEMPLATES
# ─────────────────────────────────────────────────────────────────
available_templates:
  # Level 1+ (Baseline - required at all levels)
  spec: .opencode/speckit/templates/spec.md
  plan: .opencode/speckit/templates/plan.md
  tasks: .opencode/speckit/templates/tasks.md
  # Level 2+ (Verification)
  checklist: .opencode/speckit/templates/checklist.md
  # Level 3 (Full)
  decision_record: .opencode/speckit/templates/decision-record.md
  # Optional (any level)
  research: .opencode/speckit/templates/research.md
  research_spike: .opencode/speckit/templates/research-spike.md
  # Utility (any level)
  handover: .opencode/speckit/templates/handover.md
  debug_delegation: .opencode/speckit/templates/debug-delegation.md

# ─────────────────────────────────────────────────────────────────
# PARALLEL DISPATCH CONFIGURATION
# ─────────────────────────────────────────────────────────────────
# Smart parallel sub-agent dispatch for eligible workflow phases.
# Uses 5-dimension complexity scoring algorithm.
# Thresholds (AGENTS.md compliant): <20% = direct, ≥20% + 2 domains = ALWAYS ask
parallel_dispatch_config:
  enabled: true
  version: "1.0.0"

  # Complexity scoring algorithm (5 dimensions, weighted)
  complexity_scoring:
    domain_count:
      weight: 0.35
      domains: [code, analysis, docs, git, testing, devops]
      scoring: "1=0.0, 2=0.5, 3+=1.0"
    file_count:
      weight: 0.25
      scoring: "1-2=0.0, 3-5=0.5, 6+=1.0"
    loc_estimate:
      weight: 0.15
      scoring: "<50=0.0, 50-200=0.5, >200=1.0"
    parallel_opportunity:
      weight: 0.20
      scoring: "sequential=0.0, some=0.5, high=1.0"
    task_type:
      weight: 0.05
      scoring: "trivial=0.0, moderate=0.5, complex=1.0"

  # Decision thresholds (AGENTS.md compliant - no auto-dispatch)
  thresholds:
    direct_max: 20
    ask_min: 20
    min_domains_for_ask: 2
    # NOTE: auto_dispatch_min and min_domains_for_auto REMOVED per AGENTS.md Section 1
    # Always ask user before parallel dispatch (except Step 6 Planning)

  # Session preference (1 hour persistence)
  session_preference:
    persist_duration_seconds: 3600

  # Override phrases for power users
  override_phrases:
    direct: ["proceed directly", "handle directly", "skip parallel", "skip agents"]
    parallel: ["use parallel", "dispatch agents", "parallelize", "use agents"]
    auto: ["auto-decide", "auto mode", "decide for me"]

  # Question template for AskUserQuestion
  question_template:
    tool: AskUserQuestion
    header: "Parallel Dispatch"
    format: |
      **Phase: {phase_name}**
      Complexity: {complexity_score}% | Domains: {domain_count} ({domains_list})

      This phase may benefit from parallel sub-agents for faster execution.
    options:
      - id: A
        label: "Handle directly"
        description: "Execute phase sequentially without parallel agents"
      - id: B
        label: "Use parallel agents"
        description: "Dispatch specialized agents for faster parallel execution"
      - id: C
        label: "Auto-decide for session"
        description: "Let system decide based on complexity thresholds (1 hour)"

  # Eligible phases in this workflow
  eligible_phases:
    - step_3_specification
    - step_6_planning  # Has inline_parallel_exploration - 4 agents dispatched directly
    - step_8_analysis
    - step_10_development

# ─────────────────────────────────────────────────────────────────
# CHECKPOINT OPTIONS (Used at each step)
# ─────────────────────────────────────────────────────────────────
checkpoint_options:
  standard:
  - label: "Approve"
    description: "Approve this step and proceed to next"
  - label: "Review Details"
    description: "Show more details about what was done"
  - label: "Modify"
    description: "Request changes before proceeding"
  - label: "Skip"
    description: "Skip this step (if optional)"

# ─────────────────────────────────────────────────────────────────
# WORKFLOW (12 STEPS WITH CHECKPOINTS)
# ─────────────────────────────────────────────────────────────────
workflow:
  step_1_request_analysis:
    purpose: Analyze inputs and define development scope
    activities:
    - Analyze all user inputs thoroughly
    - Define development scope for the spec folder
    - Verify or create spec folder structure
    - Check for existing artifacts
    - Establish development scope
    deep_analysis:
      focus: comprehensive_requirement_analysis
      outputs:
      - requirement_summary
      - approach_overview
      - complexity_assessment
      - key_objectives
      - success_criteria
    validation: understanding_confirmed
    checkpoint:
      question: "Step 1 Complete: Request analysis finished. How would you like to proceed?"
      use: AskUserQuestion
      options: checkpoint_options.standard

  step_2_pre_work_review:
    purpose: Review skills folder and project standards
    activities:
    - Read and review AGENTS.md
    - Check skills folder (.claude/skills/ or .opencode/skills/) for relevant coding standards
    - Extract coding standards summary
    - Identify architectural patterns
    - Document project conventions
    required_documents:
    - AGENTS.md
    - Skills folder (if available)
    verification: MUST_REVIEW
    validation: principles_established
    checkpoint:
      question: "Step 2 Complete: Skills folder reviewed. How would you like to proceed?"
      use: AskUserQuestion
      options: checkpoint_options.standard

  step_3_specification:
    purpose: Create comprehensive feature specification

    # PRE-PHASE: Smart parallel dispatch check (AGENTS.md compliant)
    pre_phase_parallel_check:
      enabled: true
      phase_domains: [code, docs]
      complexity_boost: 0
      decision_logic: |
        BEFORE starting this phase, evaluate parallel dispatch (AGENTS.md compliant):
        1. Check for override phrases in user request
        2. Check for session preference (from previous "Auto-decide" selection)
        3. Check for sequential dependencies (skip if detected)
        4. Calculate phase complexity using parallel_dispatch_config
        5. Apply thresholds:
           - <20% → proceed directly (no parallel agents)
           - ≥20% + 2 domains → ALWAYS ask user via AskUserQuestion
           NOTE: No auto-dispatch - per AGENTS.md Section 1, always ask before parallel dispatch
      on_parallel_dispatch:
        agents:
          - name: "spec_explorer"
            focus: "Existing specifications and patterns in codebase"
            model: "sonnet"
          - name: "requirement_analyzer"
            focus: "Similar features and their requirements"
            model: "sonnet"
        dispatch_note: "Spawn agents in SINGLE message for parallel execution"
      fallback: "Proceed with activities below if dispatch fails or user chooses direct"

    activities:
    - Generate concise short name for branch
    - Check for existing branches
    - Run create-documentation.sh script
    - Estimate complexity and select documentation level using progressive enhancement:
      - "Level 1 (Baseline): <100 LOC - spec.md + plan.md + tasks.md"
      - "Level 2 (Verification): 100-499 LOC - Level 1 + checklist.md"
      - "Level 3 (Full): >=500 LOC - Level 2 + decision-record.md"
    - Load and fill spec.md
    - Generate functional requirements
    - Define success criteria
    outputs:
    - feature_branch: created
    - spec.md: acceptance_criteria
    template: .opencode/speckit/templates/spec.md
    validation: spec_complete
    checkpoint:
      question: "Step 3 Complete: Specification created. Review spec.md?"
      use: AskUserQuestion
      options: checkpoint_options.standard

  step_4_clarification:
    purpose: Resolve ambiguities and clarify requirements
    activities:
    - Extract [NEEDS CLARIFICATION] markers (max 3)
    - Research codebase for patterns
    - Resolve ambiguities through investigation
    - Update spec.md with clarifications
    - Document assumptions
    outputs:
    - resolved_ambiguities
    - clarified_requirements
    - updated_spec
    validation: requirements_clear
    checkpoint:
      question: "Step 4 Complete: Requirements clarified. How would you like to proceed?"
      use: AskUserQuestion
      options: checkpoint_options.standard

  step_5_quality_checklist:
    purpose: Generate validation checklist AND USE FOR ACTIVE VERIFICATION (Level 2+ requirement)
    level_requirement: "Level 2+ (Verification and Full)"
    activities:
    - Check documentation level - skip for Level 1, MANDATORY for Level 2+
    - Load checklist.md template
    - Generate domain-specific validation items with priorities (P0/P1/P2)
    - Create checklist file
    - FOR EACH ITEM:
      - Verify condition is met
      - Mark as [x] with evidence link
      - If not met: document blocker (P0/P1) or deferral reason (P2)
    - Ensure ALL P0 items are complete (HARD BLOCKER)
    - Ensure ALL P1 items are complete or user-approved deferral
    - Document P2 deferrals with reasons
    - Update checklist.md file with verification marks
    verification_protocol:
      p0_handling: "BLOCKER - Cannot proceed without completion"
      p1_handling: "Required - Complete or get user approval to defer"
      p2_handling: "Optional - Can defer with documented reason"
    outputs:
    - quality_checklist: generated
    - checklist_status: pass_or_fail
    - verified_items_count: "X/Y items verified"
    - p0_status: "all_complete or blocked"
    - deferred_items: list_of_deferred_p2_items
    template: .opencode/speckit/templates/checklist.md
    validation: checklist_verified_and_marked
    checkpoint:
      question: "Step 5 Complete: Checklist verified. How would you like to proceed?"
      use: AskUserQuestion
      options:
      - label: "Proceed"
        description: "Continue to planning phase"
      - label: "Review Verification"
        description: "Show checklist verification details"
      - label: "Address Blockers"
        description: "Fix P0/P1 blockers first"

  step_6_planning:
    purpose: Create technical plan with implementation approach

    # INLINE 4-AGENT PARALLEL EXPLORATION
    # Self-contained exploration - no external skill dependency
    parallel_dispatch_note: |
      This phase dispatches 4 parallel Sonnet agents directly via Task tool.
      Agents: Architecture Explorer, Feature Explorer, Dependency Explorer, Test Explorer.
      No additional question is asked because parallel dispatch is integral to this phase.

    # 4-Agent Parallel Exploration Configuration
    inline_parallel_exploration:
      description: "4-agent parallel exploration for verified planning"
      purpose: "Spawn 4 Explore agents to discover codebase patterns before planning"

      execution:
        tool: Task
        subagent_type: Explore
        model: sonnet  # Fast, cost-effective exploration (works in both Claude Code and OpenCode)
        parallel: true  # All 4 agents spawn in single message

      agents:
        architecture_explorer:
          focus: "Project structure, entry points, component connections"
          purpose: "Understand system architecture"
          prompt: |
            Explore the codebase to find how the system architecture works for: {task_description}

            Return:
            1. Your hypothesis about the architecture
            2. Full paths to all relevant files (e.g., /path/to/file.ts:lineNumber)
            3. Any patterns you noticed (component structure, module organization, etc.)

            Do NOT draw conclusions - just report findings. The main agent will verify.

        feature_explorer:
          focus: "Similar features, related patterns"
          purpose: "Find reusable patterns"
          prompt: |
            Explore the codebase to find similar features or related patterns for: {task_description}

            Return:
            1. Your hypothesis about existing similar features
            2. Full paths to all relevant files
            3. Any patterns you noticed (naming conventions, implementation patterns, etc.)

            Do NOT draw conclusions - just report findings.

        dependency_explorer:
          focus: "Imports, modules, affected areas"
          purpose: "Identify integration points"
          prompt: |
            Explore the codebase to find dependencies and integration points for: {task_description}

            Return:
            1. Your hypothesis about which modules/files will be affected
            2. Full paths to all relevant files
            3. Any patterns you noticed (dependency chains, coupling points, etc.)

            Do NOT draw conclusions - just report findings.

        test_explorer:
          focus: "Test patterns, testing infrastructure"
          purpose: "Understand verification approach"
          prompt: |
            Explore the codebase to find test patterns and testing infrastructure.

            Return:
            1. Your hypothesis about how testing works in this project
            2. Full paths to all relevant test files
            3. Any patterns you noticed (test frameworks, mocking patterns, coverage expectations, etc.)

            Do NOT draw conclusions - just report findings.

      verification:
        description: "After agents return, verify hypotheses by reading identified files"
        approach:
          - "Read each file identified by Explore agents"
          - "Verify or refute each hypothesis"
          - "Cross-reference findings across agents for consistency"
          - "Build complete mental model of architecture, affected components, integration points, risks"
          - "Resolve conflicting hypotheses by reading additional files"

      outputs:
        - architecture_findings
        - feature_findings
        - dependency_findings
        - test_findings
        - verified_mental_model

      fallback:
        on_failure: "Use inline planning activities below"
        reason: "Graceful degradation if agents unavailable"

    # FALLBACK: Inline planning if exploration fails
    activities:
    - Run check-prerequisites.sh --json --paths-only
    - Load plan.md
    - Fill Technical Context
    - Fill Constitution Check section
    - Phase 0: Generate research.md to resolve unknowns
    - Phase 1: Generate data-model.md, contracts/
    - Generate Testing Strategy
    - Generate Success Metrics
    - Import Risk Matrix from spec
    - Generate Dependencies Tables
    - Generate Phase 2-4 outlines
    outputs:
    - plan.md: technical_approach
    - research.md: resolved_unknowns
    template: .opencode/speckit/templates/plan.md
    validation: approach_defined
    checkpoint:
      question: "Step 6 Complete: Technical plan created. Review plan.md?"
      use: AskUserQuestion
      options: checkpoint_options.standard

  step_7_task_breakdown:
    purpose: Break plan into executable tasks (Level 1+ requirement)
    level_requirement: "Level 1+ (Baseline - required at all levels)"
    activities:
    - Load plan.md for tech stack and architecture
    - Load spec.md for user stories and priorities
    - Generate tasks organized by user story
    - Create dependency graph
    - Mark parallel-executable tasks with [P]
    - Define task phases
    - Generate time estimates
    - Create tasks.md (required at all levels)
    outputs:
    - tasks.md: implementation_breakdown
    template: .opencode/speckit/templates/tasks.md
    validation: tasks_documented
    checkpoint:
      question: "Step 7 Complete: Tasks broken down. Review tasks.md?"
      use: AskUserQuestion
      options: checkpoint_options.standard

  step_8_analysis:
    purpose: Verify consistency across all artifacts

    # PRE-PHASE: Smart parallel dispatch check (AGENTS.md compliant)
    pre_phase_parallel_check:
      enabled: true
      phase_domains: [code, docs, analysis]
      complexity_boost: 10
      decision_logic: |
        BEFORE starting this phase, evaluate parallel dispatch (AGENTS.md compliant):
        1. Check for override phrases in user request
        2. Check for session preference (from previous "Auto-decide" selection)
        3. Check for sequential dependencies (skip if detected)
        4. Calculate phase complexity using parallel_dispatch_config
        5. Apply thresholds:
           - <20% → proceed directly (no parallel agents)
           - ≥20% + 2 domains → ALWAYS ask user via AskUserQuestion
           NOTE: No auto-dispatch - per AGENTS.md Section 1, always ask before parallel dispatch
      on_parallel_dispatch:
        agents:
          - name: "consistency_analyzer"
            focus: "Cross-artifact consistency and requirement coverage"
            model: "sonnet"
          - name: "gap_detector"
            focus: "Missing requirements, underspecification, edge cases"
            model: "sonnet"
        dispatch_note: "Spawn agents in SINGLE message for parallel execution"
      fallback: "Proceed with activities below if dispatch fails or user chooses direct"

    activities:
    - Build requirements inventory
    - Build task coverage mapping
    - Run consistency checks
    - Generate gap analysis
    outputs:
    - consistency_report
    - coverage_verification
    validation: consistency_verified
    checkpoint:
      question: "Step 8 Complete: Consistency analysis done. How would you like to proceed?"
      use: AskUserQuestion
      options: checkpoint_options.standard

  step_9_implementation_check:
    purpose: Verify all prerequisites for implementation
    activities:
    - Run check-prerequisites.sh --json --require-tasks
    - Verify environment ready
    - Check API endpoints accessible
    - Verify dependencies loaded
    - Confirm no blockers
    checks:
      prerequisites: verified
      blockers: none
      environment: ready
    validation: prerequisites_verified
    checkpoint:
      question: "Step 9 Complete: Ready to implement. Proceed with development?"
      use: AskUserQuestion
      options:
      - label: "Start Development"
        description: "Begin implementation phase"
      - label: "Review Plan"
        description: "Review technical plan before proceeding"
      - label: "Hold"
        description: "Pause before implementation"

  step_10_development:
    purpose: Execute implementation following task plan

    # PRE-PHASE: Smart parallel dispatch check (AGENTS.md compliant)
    pre_phase_parallel_check:
      enabled: true
      phase_domains: [code, testing]
      complexity_boost: 15
      decision_logic: |
        BEFORE starting this phase, evaluate parallel dispatch (AGENTS.md compliant):
        1. Check for override phrases in user request
        2. Check for session preference (from previous "Auto-decide" selection)
        3. Check for sequential dependencies (skip if detected)
        4. Calculate phase complexity using parallel_dispatch_config
        5. Apply thresholds:
           - <20% → proceed directly (no parallel agents)
           - ≥20% + 2 domains → ALWAYS ask user via AskUserQuestion
           NOTE: No auto-dispatch - per AGENTS.md Section 1, always ask before parallel dispatch
      on_parallel_dispatch:
        agents:
          - name: "implementation_agent"
            focus: "Core implementation tasks from tasks.md"
            model: "sonnet"
          - name: "test_agent"
            focus: "Test implementation and validation"
            model: "sonnet"
        dispatch_note: "Spawn agents in SINGLE message for parallel execution"
        warning: "Development tasks may have dependencies - verify task order"
      fallback: "Proceed with activities below if dispatch fails or user chooses direct"

    activities:
    - Parse tasks.md structure
    - Execute phase by phase
    - Setup first (structure, dependencies, config)
    - Follow TDD approach where applicable
    - Core development (models, services, endpoints)
    - Integration work (database, middleware, logging)
    - Update task checklist progressively (mark [X])
    - Log progress after each task
    approach: incremental_implementation_with_reviews
    requirements:
    - follow: Check skills folder for coding standards
    - update: task_checklist_progressively
    - test: before_commit
    - validate: continuously
    validation: development_complete
    checkpoint:
      question: "Step 10 Complete: Development finished. Review implementation?"
      use: AskUserQuestion
      options:
      - label: "Review Code"
        description: "Show code changes for review"
      - label: "Run Tests"
        description: "Execute test suite"
      - label: "Continue"
        description: "Proceed to completion"

  step_11_completion:
    purpose: Generate implementation summary
    activities:
    - Verify all tasks completed
    - Validate tests pass
    - Confirm implementation follows plan
    - Generate implementation-summary.md
    - Update all task status
    summary_document:
      location: "[SPEC_FOLDER]/implementation-summary.md"
      required_sections:
      - feature_branch_name
      - files_modified_created
      - verification_steps_taken
      - deviations_from_plan
      - recommended_next_steps
    verification_summary:
      checklist_verification:
        required: true  # for Level 2+
        must_include:
        - Total items verified count
        - P0 items status (all must be complete)
        - P1 items status (all complete or deferred with approval)
        - Deferred P2 items with reasons
        - Link to updated checklist.md
    validation: implementation_complete
    checkpoint:
      question: "Step 11 Complete: Implementation summary generated. Review summary?"
      use: AskUserQuestion
      options: checkpoint_options.standard

  step_12_save_context:
    purpose: Save conversation context
    activities:
    - Invoke workflows-memory skill
    - Preserve development decisions
    - Preserve debugging insights
    - Preserve code changes
    tool_invocation:
      tool: Skill
      parameter: skill="workflows-memory"
      note: "Use the Skill tool with skill parameter to activate context saving"
    outputs:
    - context_file: "[SPEC_FOLDER]/memory/[DD-MM-YY_HH-MM]__session.md"
    validation: context_saved_successfully
    checkpoint:
      question: "Step 12 Complete: Context saved. Workflow finished!"
      use: AskUserQuestion
      options:
      - label: "Done"
        description: "Complete the workflow"
      - label: "View Summary"
        description: "Show final summary"

# ─────────────────────────────────────────────────────────────────
# WORKFLOW TERMINATION
# ─────────────────────────────────────────────────────────────────
termination:
  after_step: 12
  message: "SpecKit workflow completed successfully. Workflow terminated after step 12 (save context)."

# ─────────────────────────────────────────────────────────────────
# INTERACTIVE EXECUTION GUIDANCE
# ─────────────────────────────────────────────────────────────────
interactive_execution:
  principle: "Execute workflow steps with user approval at each checkpoint"

  checkpoint_behavior:
  - Complete step activities
  - Present results summary
  - Use AskUserQuestion for approval
  - Wait for user response
  - Process user feedback
  - Proceed or modify as directed

  user_feedback_handling:
    approve: "Proceed to next step"
    review: "Show detailed output of current step"
    modify: "Accept changes and re-execute step"
    skip: "Skip optional step and proceed"

# ─────────────────────────────────────────────────────────────────
# ERROR RECOVERY
# ─────────────────────────────────────────────────────────────────
error_recovery:
  step_validation_fails:
    action: "Review requirements, ask clarifying questions, retry step"
  user_rejects_approach:
    action: "Present alternatives, modify plan, document decision"
  tests_fail:
    action: "Debug, fix, re-run before marking complete"
  prerequisites_insufficient:
    action: "Return to prior workflow phase or ask user for guidance"
  environment_unavailable:
    action: "Skip browser testing, document limitation"

# ─────────────────────────────────────────────────────────────────
# RULES
# ─────────────────────────────────────────────────────────────────
rules:
  ALWAYS:
  - follow_workflow_sequence
  - document_all_changes
  - validate_before_completion
  - use_devtools_for_staging_analysis
  - pause_at_checkpoints_for_approval
  - respect_user_feedback
  - limit_context_to_active_scope
  - use_checklist_for_verification_level_2_plus
  - mark_checklist_items_with_evidence
  - complete_all_p0_items_before_done
  - get_user_approval_for_p1_deferrals

  NEVER:
  - skip_workflow_steps
  - ignore_blockers
  - submit_without_validation
  - skip_browser_testing
  - proceed_without_user_approval
  - ignore_user_modification_requests
  - claim_completion_without_checklist_verification_level_2_plus
  - skip_p0_checklist_items
  - defer_p1_items_without_user_approval
